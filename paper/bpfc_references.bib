@article{doyle2025,
  title   = {Absorbing Discrete Diffusion Language Models Implement Exact Bayesian Posteriors},
  author  = {Doyle, Patrick},
  journal = {arXiv preprint arXiv:2507.07586},
  year    = {2025},
  url     = {https://arxiv.org/abs/2507.07586}
}

@article{nie2024,
  title   = {{LLaDA}: Large Language Diffusion with mAsking},
  author  = {Nie, Shen and others},
  journal = {arXiv preprint arXiv:2502.09992},
  year    = {2024},
  url     = {https://arxiv.org/abs/2502.09992}
}

@misc{inclAI2025,
  title        = {{LLaDA} 2.0-mini: Scaling Masked Diffusion LMs to 16B Parameters},
  author       = {{inclusionAI}},
  howpublished = {\url{https://huggingface.co/inclusionAI/LLaDA-2.0-mini}},
  year         = {2025}
}

@article{sahoo2024,
  title   = {{MDLM}: Masked Diffusion Language Model},
  author  = {Sahoo, Subham and others},
  journal = {arXiv preprint arXiv:2406.07524},
  year    = {2024}
}

@article{lou2024,
  title   = {{SEDD}: Score Entropy Discrete Diffusion},
  author  = {Lou, Aaron and others},
  journal = {arXiv preprint arXiv:2310.16834},
  year    = {2024}
}

@article{kuhn2023,
  title   = {Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation},
  author  = {Kuhn, Lorenz and Gal, Yarin and Farquhar, Sebastian},
  journal = {arXiv preprint arXiv:2302.09664},
  year    = {2023}
}

@article{guo2017,
  title   = {On Calibration of Modern Neural Networks},
  author  = {Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q.},
  journal = {arXiv preprint arXiv:1706.04599},
  year    = {2017}
}

@inproceedings{angelopoulos2022,
  title     = {Conformal Risk Control},
  author    = {Angelopoulos, Anastasios N. and others},
  booktitle = {ICLR 2022},
  year      = {2022}
}

@article{kadavath2022,
  title   = {Language Models (Mostly) Know What They Know},
  author  = {Kadavath, Saurav and others},
  journal = {arXiv preprint arXiv:2207.05221},
  year    = {2022}
}

@article{czec2025,
  title   = {Confusion Zones and Epistemic Calibration in Discrete Diffusion Models},
  author  = {[Author TBD]},
  journal = {arXiv preprint arXiv:2511.15208},
  year    = {2025},
  note    = {Identified via literature search; author names TBD}
}

@article{gautam2026,
  title   = {{DiffuTruth}: Hallucination Detection via Diffusion-Based Generative Stress Testing},
  author  = {Gautam, Vikram and others},
  journal = {arXiv preprint arXiv:2602.11364},
  year    = {2026}
}

@inproceedings{joshi2017,
  title     = {{TriviaQA}: A Reading Comprehension Dataset over Trivia Questions},
  author    = {Joshi, Mandar and Choi, Eunsol and Weld, Daniel S. and Zettlemoyer, Luke},
  booktitle = {ACL 2017},
  year      = {2017}
}

@article{petroni2019,
  title   = {Language Models as Knowledge Bases?},
  author  = {Petroni, Fabio and others},
  journal = {arXiv preprint arXiv:1909.01066},
  year    = {2019}
}

@article{mallen2022,
  title   = {When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories},
  author  = {Mallen, Alex and others},
  journal = {arXiv preprint arXiv:2212.10511},
  year    = {2022}
}

@inproceedings{austin2021,
  title     = {Structured Denoising Diffusion Models in Discrete State-Spaces},
  author    = {Austin, Jacob and others},
  booktitle = {NeurIPS 2021},
  year      = {2021}
}
