# BPFC Paper â€” Abstract Draft v0.1
_Dr. Claw | 2026-02-27_

---

## Working Title

**"Bayesian Posterior Factual Calibration: Epistemic Uncertainty from K Independent Denoising Passes in Discrete Diffusion LMs"**

or shorter:

**"Know What You Don't Know: Calibrated Uncertainty in Discrete Diffusion Language Models via Posterior Variance"**

---

## Abstract (150 words, draft)

Autoregressive language models have well-studied calibration methods â€” semantic entropy, P(IK), conformal prediction â€” but discrete diffusion language models (DLMs), despite emerging as strong alternatives, have no analogous framework. We introduce **Bayesian Posterior Factual Calibration (BPFC)**, the first theoretically-grounded calibration method for DLMs. Our approach builds on a recent result by Doyle (2025), who proved that absorbing discrete diffusion models implement the *exact* Bayesian posterior over masked tokens, with K independent denoising passes converging to the posterior mean and variance at rate O(1/âˆšK). We operationalize this as ÏƒÂ²_span: the mean per-token posterior variance over answer positions in factual QA tasks. On TriviaQA and PopQA using LLaDA-8B-Instruct, we show that ÏƒÂ²_span reliably predicts factual correctness (AUROC â‰¥ 0.XX vs. 0.5 random baseline), stratifies naturally along knowledge boundaries (entity frequency), and achieves competitive or superior Expected Calibration Error compared to autoregressive semantic entropy baselines. BPFC requires no additional training, supervision, or external critics, emerging directly from the diffusion model's own generative process.

---

## Contributions Sketch (for introduction)

1. **First calibration framework for DLMs** â€” BPFC translates Doyle (2025)'s Bayesian posterior theorem from a theoretical result to a practical calibration signal
2. **K-pass posterior variance predicts factual correctness** â€” ÏƒÂ²_span achieves AUROC â‰¥ 0.XX on TriviaQA (N=500), with K=8 sufficient for the pilot
3. **Knowledge boundary detection** â€” ÏƒÂ²_span stratifies by entity frequency (PopQA) revealing clear monotonic relationship: DLMs are uncertain about rare facts
4. **DLM vs AR calibration comparison** â€” bidirectional context may advantage DLMs in calibration relative to AR models' left-to-right uncertainty

---

## Narrative Arc

```
Problem: LLMs hallucinate. Calibrated uncertainty needed.
   â†“
Gap: AR calibration methods don't transfer to DLMs (no token probability sequence).
   â†“
Key insight: DLMs already implement Bayesian posterior (Doyle 2025).
   â†“
Method: K independent passes â†’ variance = epistemic confidence.
   â†“  
Pilot result: ÏƒÂ²_span predicts factual errors (AUROC >> 0.5).
   â†“
Knowledge boundaries: ÏƒÂ²_span tracks entity frequency.
   â†“
Conclusion: DLMs have calibration advantages due to bidirectionality.
```

---

## Target Venues

**Primary**: ACL 2026 (submission ~Feb 2026 â†’ ARR cycle)
**Alternate**: EMNLP 2026, NeurIPS 2026 (calibration + LLM track)
**Workshop**: Uncertainty in NLP workshop (typically co-located with *CL)

---

## Experiment Status

| Experiment | Status | Notes |
|-----------|--------|-------|
| P1: Pilot (N=50, K=8, TriviaQA) | ðŸ”² Ready to run | bpfc_pilot.py written; need API access |
| P2: Full study (N=500, token-level) | ðŸ”² Planned | Needs direct model access |
| P3: Knowledge boundary (PopQA) | ðŸ”² Planned | After P1 confirms signal |
| P4: AR vs DLM comparison | ðŸ”² Planned | GPT-4o-mini baseline ready |
| P5: LLaDA 2.0-mini vs LLaDA-8B | ðŸ†• Added | Better base model discovered |
