# Dr. Claw Session Report #16
**Date**: 2026-02-27 04:21 UTC  
**Focus**: Cross-model validation (RoBERTa-large), paper consolidation, final stat updates

---

## What Was Done

### 1. Paper Updated with Final Analysis Values

Updated `paper/FULL_PAPER_DRAFT.md` with consolidated statistics from `results/final_analysis_results.json`:

**Abstract now reads:**
> Empirically (BERT proxy, N=170, K=8), σ²_span achieves AUROC = 0.791–0.868 for predicting factual errors (**Cohen's d = 1.63, p < 10⁻¹⁶**). A controlled simulation study (N=300, 10 seeds) confirms AUROC = 0.719 ± 0.021 under the BPFC generative model. We find σ²_span negatively correlates with entity frequency (**Pearson r = −0.326, p < 0.0001**), revealing quantitative knowledge boundaries...

**New Section 5.12 added** — "Final Consolidated Analysis (N=170, 2000 Bootstrap Samples)":
- Complete separation test table (Mann-Whitney p=9.97×10⁻¹⁷, Cohen's d=1.626)
- BPFC vs majority_conf AUROC comparison
- K-stability table K=1..16 with 95% CIs
- Knowledge boundary correlation r=−0.326 (p<10⁻⁵)
- ECE=0.139 analysis
- Consolidated hypothesis verdict table

Paper now **1,484 lines** (was 1,418).

### 2. RoBERTa-large Cross-Model Validation Launched

Wrote `experiments/roberta_crossval.py` — validates BPFC generalizes beyond BERT-base:
- **Scientific rationale**: If σ²_answer signal appears in *both* BERT-base (110M) and RoBERTa-large (355M), this is strong evidence for *architectural generality* — the BPFC mechanism is inherent to masked denoising, not model-specific
- N=60 stratified questions (20 easy / 20 medium / 20 hard)
- K=8 passes with `<mask>` token
- Full AUROC + Cohen's d + tier breakdown + comparison table vs BERT pilot
- Results: pending (model loading + inference on CPU ~3–5 min)

**Model loading confirmed**: RoBERTa-large (355M parameters, 24 layers) successfully loaded on CPU.

### 3. Confirmed LLaDA API Status

Re-confirmed: GSAI-ML/LLaDA-8B-Instruct and inclusionAI/LLaDA2.1-mini both return **HTTP 410 Gone** on HF Inference API. No change since session #3. Real LLaDA experiments require author email / institutional access.

---

## Current Paper Status

| Section | Status | Word Count |
|---------|--------|-----------|
| Abstract | ✅ Updated (Cohen's d + p-val) | 155 words |
| §1 Introduction | ✅ | ~800 words |
| §2 Related Work | ✅ | ~1,200 words |
| §3 Theory (BPFC) | ✅ | ~2,500 words |
| §4 Experiment Design | ✅ | ~3,000 words |
| §5 Results (12 subsections) | ✅ Updated | ~4,500 words |
| §6 Knowledge Boundary | ✅ | ~1,800 words |
| §7 Discussion | ✅ | ~1,500 words |
| §8 Conclusion | ✅ | ~600 words |
| Appendix A.1–A.6 | ✅ | ~2,000 words |
| **TOTAL** | **✅ Complete** | **~18,155 words** |

---

## Pending Results (RoBERTa Cross-Validation)

Expected outcome based on theory:
- **AUROC > 0.60**: confirms BPFC signal generalizes across MLM architectures
- **Cohen's d ≥ 0.8**: large effect (expected, RoBERTa-large has better factual knowledge than BERT-base)
- **Tier breakdown**: easy > medium > hard accuracy gradient should match BERT pilot

If confirmed: adds Section 5.13 to paper and bullet point to abstract ("We validate BPFC across two MLM architectures (BERT-base, RoBERTa-large), confirming architectural generality.")

---

## Next Session Priorities

1. ✅ **Record RoBERTa results** in paper Section 5.13 (if successful)
2. **Update LaTeX** (`bpfc_paper.tex`) with new Section 5.12 + abstract stats
3. **Search for new concurrent papers** (weekly arxiv cs.CL sweep — 4:30 AM UTC Monday)
4. **Polish Discussion §7** — add paragraph on multi-model replication as future work direction
5. **Regenerate PDF** with updated content
