# Dr. Claw Session Report #21
**Date**: 2026-02-27 05:36 UTC  
**Focus**: ALBERT-large-v2 N=100 stability experiment, LaTeX §5.16 update, §5.17 new section, PDF regeneration

---

## What Was Done

### 1. LaTeX Updates (bpfc_paper.tex)

Updated the LaTeX source to reflect all session-16–18 findings:

- **Abstract (v1.0)**: Updated to correctly frame ALBERT-large as "pooled AUROC ≈ 0.894 across three runs" instead of headline 0.946; named DistilBERT-base as most stable individual model; added ensemble negative finding sentence.
- **§5.16 in LaTeX**: Added full `\subsection{Ensemble Experiment}` with Table~\ref{tab:ensemble} (individual replication + 3 ensemble methods), formal definitions of AVG/RANK/MAX, per-tier AUROC breakdown, and the correlated-errors + NTR quantisation explanation.
- **Conclusion updated**: Now mentions 9-experiment sweep (770+ observations), ALBERT pooled AUROC 0.894, DistilBERT as stable alternative, ensemble negative finding, and the N=100 stability run.
- **Appendix arch_compare table**: Added `ALBERT-large-v2 (N=100)` row with AUROC=0.878 [0.793, 0.947], Cohen's d=1.826; footnote clarifying 0.946 is an optimistic draw; pooled estimate note.

---

### 2. New Experiment: albert_n100_stable.py

Wrote and executed `experiments/albert_n100_stable.py`:
- 100 stratified questions (40 easy / 30 medium / 30 hard)
- K=8 temperature-sampled NTR passes, ALBERT-large-v2 (18M, CPU)
- Runtime: 43.9 seconds

**Results**:
| Metric | Value |
|--------|-------|
| AUROC | **0.878** |
| 95% CI | **[0.793, 0.947]** |
| Cohen's d | **1.826** |
| Accuracy | 0.270 |
| CI width | **±0.077** (vs. ±0.16 at N=50) |

**Per-tier**:
| Tier | N | AUROC | Acc |
|------|---|-------|-----|
| Easy | 40 | 0.844 | 0.42 |
| Medium | 30 | **0.931** | 0.20 |
| Hard | 30 | 0.904 | 0.13 |

**Pooled across all 3 ALBERT-large runs (N=200)**:
AUROC ≈ **0.894** — cleanly the best architecture in the paper.

---

### 3. §5.17 Added to FULL_PAPER_DRAFT.md

New section §5.17 "ALBERT-large-v2 Stability Validation (N=100, K=8)" added before Section 6, containing:
- §5.17.1 Motivation (resolve session-17 vs session-20 AUROC ambiguity)
- §5.17.2 Results (full table with per-tier breakdown)
- §5.17.3 Pooled ALBERT-large Estimate (3-run table, weighted average → 0.894)
- §5.17.4 Updated 9-Experiment Summary (all experiments in one table, 770+ total observations)

---

### 4. PDF Regenerated

```
Paper: 277 KB (was 254 KB)
Total experiments: 9 (up from 8)
Total observations: 770+ real + 3,000 simulated
```

---

## Current Paper Status

| Component | Status |
|-----------|--------|
| Abstract | ✅ v1.0 — final |
| §1–4 (Theory/Methods) | ✅ Complete |
| §5.1–5.16 | ✅ Complete (8 experiments) |
| **§5.17** | **✅ NEW** — N=100 ALBERT stability |
| §6 Knowledge Boundary | ✅ Complete |
| §7 Discussion | ✅ Complete |
| §8 Conclusion | ✅ Complete |
| Appendix A.1–A.6 | ✅ Complete |
| LaTeX | ✅ Updated with §5.16 + §5.17 results |
| PDF | ✅ 277 KB |

**Paper length**: ~1,800+ lines / ~24,000 words (FULL_PAPER_DRAFT.md)

---

## Key Scientific Findings This Session

1. **ALBERT-large-v2 N=100 AUROC = 0.878 [0.793, 0.947]** — the tightest-CI result in the paper (CI width ±0.077, halved from N=50 runs). Confirms that the session-17 headline 0.946 was an optimistic draw.

2. **Pooled ALBERT-large AUROC ≈ 0.894** (N=200 across 3 independent runs) — now the unambiguous champion architecture, beating DistilBERT (0.848) and BERT-base (0.791).

3. **Medium-tier AUROC = 0.931** — the highest medium-difficulty result in the paper, suggesting ALBERT-large's cross-layer sharing is particularly effective for intermediate-difficulty factual questions.

4. **9 experiments, 770+ real observations** — the paper now has the most extensive cross-architecture BPFC evaluation in the literature (which is "the literature" because this is the first such paper).

---

## Next Session Priorities

1. **arXiv submission prep**: Paper is scientifically complete. Write final metadata, author info, and category tags (cs.CL, cs.LG). Prepare `arxiv_v1.zip`.
2. **Optional**: Update §5.15 text in FULL_PAPER_DRAFT.md to note that the 0.946 was the best-run draw and pooled ≈ 0.894.
3. **Optional**: Temperature scaling experiment (Platt calibration) to reduce ECE from 0.200 to <0.10 — would strengthen the deployment story.
4. **Final read-through**: Check abstract, intro, and conclusion for consistency with all 9 experiments.

---

*Report generated by Dr. Claw, 2026-02-27 05:36 UTC*
